{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Hybrid Search ??\n",
    "\n",
    "Hybrid Search is a search technique that combines both dense vector search (based on embeddings capturing semantic meaning) and traditional keyword-based search (sparse search) to retrieve the most relevant results. It leverages the strengths of both approaches to improve search accuracy and relevance, especially in scenarios like information retrieval and question-answering systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Pinecone ??\n",
    "Pinecone is a managed vector database designed for similarity search and real-time analytics. It helps store and search high-dimensional vectors efficiently.\n",
    "\n",
    "In hybrid search, Pinecone can enhance search capabilities by combining traditional keyword search with vector-based search. It allows you to index and search complex data such as embeddings from machine learning models, making it easier to retrieve relevant results based on semantic similarity, alongside traditional text-based queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.retrievers import PineconeHybridSearchRetriever\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Index Name in Pinecone\n",
    "index_name = \"hybrid-search-with-pinecone\"\n",
    "\n",
    "# Initialize the Pinecone Client\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key= PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susovanpatra/Langchain-Practicals-and-Projects/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ") model_name='all-MiniLM-L6-v2' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    }
   ],
   "source": [
    "# Importing Embedding Model for Dense Vector Search\n",
    "\n",
    "HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "print(embeddings)\n",
    "word_embedding_dimension = embeddings.client[1].word_embedding_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating The Pinecone Index For The First Time\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name= index_name,\n",
    "        dimension= word_embedding_dimension,\n",
    "        metric= \"dotproduct\",\n",
    "        spec= ServerlessSpec(cloud= 'aws', region='us-east-1')\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susovanpatra/Langchain-Practicals-and-Projects/venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.splade_encoder.SpladeEncoder at 0x3087bf190>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imorting Embedding for Keyword-based Search or Sparse Search (with TFIDF)\n",
    "\n",
    "from pinecone_text.sparse import SpladeEncoder\n",
    "\n",
    "splade = SpladeEncoder()\n",
    "splade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"I am Susovan\",\n",
    "    \"I am from India\",\n",
    "    \"MS Dhoni is the best captain in cricket till now.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vector = splade.encode_documents(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = PineconeHybridSearchRetriever(embeddings= embeddings, sparse_encoder= splade, index= index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PineconeHybridSearchRetriever(embeddings=HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), sparse_encoder=<pinecone_text.sparse.splade_encoder.SpladeEncoder object at 0x3087bf190>, index=<pinecone.data.index.Index object at 0x173957010>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "retriever.add_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I am from India'),\n",
       " Document(page_content='I am Susovan'),\n",
       " Document(page_content='MS Dhoni is the best captain in cricket till now.')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('Where I am from?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='MS Dhoni is the best captain in cricket till now.'),\n",
       " Document(page_content='I am from India'),\n",
       " Document(page_content='I am Susovan')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('Who is the best captain in cricket till now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
