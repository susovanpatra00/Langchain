{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Q&A Chatbot\n",
    "In many Q&A applications we want to allow the user to have a back-and-forth conversation, meaning the application needs some sort of \"memory\" of past questions and answers, and some logic for incorporating those into its current thinking.\n",
    "\n",
    "In this guide we focus on adding logic for incorporating historical messages. Further details on chat history management is covered in the previous videos.\n",
    "\n",
    "We will cover two approaches:\n",
    "\n",
    "- Chains, in which we always execute a retrieval step;\n",
    "- Agents, in which we give an LLM discretion over whether and how to execute a retrieval step (or multiple steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader                  # Data Ingestion\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter             # Data Transformation\n",
    "from langchain.embeddings import OllamaEmbeddings                               # Embedding\n",
    "from langchain_chroma import Chroma                                             # Vector Store\n",
    "from langchain_core.prompts import ChatPromptTemplate                           # Prompt Template\n",
    "from langchain_groq import ChatGroq                                             # LLM\n",
    "from langchain.chains import create_retrieval_chain                             # Retrieval Chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Ingestion\n",
    "#    Load, chunk and index the contents of the blog to create a retriever.\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Transformation\n",
    "#    We will convert the document into chunks for processing\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embedding\n",
    "#    After converting the documents into chunks we need to convert those into vectors\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"gemma2:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Vector Database \n",
    "#    We have created the ebeddings, now need to apply those embeddings and store it into database.\n",
    "\n",
    "vector_store = Chroma.from_documents(documents= chunks,embedding= embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x11797faf0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Retrieval Chain\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Prompt Template\n",
    "\n",
    "system_prompt = (\n",
    "    \"\"\"\n",
    "        You are an assistant for question-answering tasks.\n",
    "        Use the following pieces of retrieved context to answer\n",
    "        the question. If you don't know the answer, say that you \n",
    "        don't know. Use three sentences at maximum and keep the\n",
    "        answer concise.\n",
    "        \\n\\n\n",
    "        {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. LLM Initialisation\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Question Answer Chain & RAG Chain\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Retrieval Chain (`create_retrieval_chain`)**:\n",
    "   - **Purpose**: The retrieval chain is responsible for fetching relevant documents or information from a knowledge base (e.g., a vector store) based on the user's query.\n",
    "   - **How it works**:\n",
    "     - When the user asks a question, the retrieval chain searches through the stored documents to find the most relevant pieces of information.\n",
    "     - It uses embeddings to represent both the query and the documents as vectors, allowing it to calculate similarities and identify the closest matches.\n",
    "     - The retrieved documents are then passed to the next chain for further processing.\n",
    "   - **Key Components**:\n",
    "     - **Embeddings**: Convert text into vector representations. Here, `OllamaEmbeddings` are used to generate these vectors.\n",
    "     - **Vector Store**: Stores the document embeddings. `Chroma` is used as the vector store, enabling fast retrieval based on vector similarity.\n",
    "\n",
    "### 2. **Combination Chain (`create_stuff_documents_chain`)**:\n",
    "   - **Purpose**: The combination chain takes the documents retrieved by the retrieval chain and synthesizes them into a single coherent response.\n",
    "   - **How it works**:\n",
    "     - After receiving the relevant documents from the retrieval chain, the combination chain processes these documents to generate a concise and contextually accurate response to the user's query.\n",
    "     - This involves summarizing, rephrasing, or directly extracting content from the documents to form the final output.\n",
    "   - **Key Components**:\n",
    "     - **LLM (Language Model)**: The LLM is responsible for understanding the context of the retrieved documents and generating the final text. In this case, the `ChatGroq` model is used.\n",
    "\n",
    "### How the Chains Work Together:\n",
    "- **Step 1**: The user inputs a question.\n",
    "- **Step 2**: The **Retrieval Chain** processes the question, searches the vector store, and retrieves the most relevant documents.\n",
    "- **Step 3**: The **Combination Chain** takes these documents and creates a structured response, which is then returned to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Self Reflection?',\n",
       " 'context': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
       "  Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.')],\n",
       " 'answer': 'Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\":\"What is Self Reflection?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# create_history_aware_retriever - This works as a retriever but it is aware of the history of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Contextualized Prompt\n",
    "\n",
    "contextualized_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualized_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x11797faf0>))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x127ff7e20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x123a9c9d0>, model_name='Llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x11797faf0>)), config={'run_name': 'chat_retriever_chain'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes.\n"
     ]
    }
   ],
   "source": [
    "chat_history=[]\n",
    "\n",
    "question=\"What is Self-Reflection\"\n",
    "response1 = rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content = response1[\"answer\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "question2 = \"Tell me more about it?\"\n",
    "response2 = rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "\n",
    "print(response2['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Self-Reflection'),\n",
       " AIMessage(content='According to the provided context, Self-Reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a process in which a complex task is broken down into smaller, more manageable subtasks or steps. This can be done by a Large Language Model (LLM) using simple prompting, task-specific instructions, or human inputs. The goal of task decomposition is to make it easier to solve the original task by focusing on one step at a time.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is Task Decomposition?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Common ways of doing task decomposition include:\\n\\n1. Chain of Thought (CoT): Instructing the model to \"think step by step\" to utilize more test-time computation and decompose hard tasks into smaller and simpler steps.\\n2. History-based prompting: Presenting a history of sequentially improved outputs in context and training the model to take on the trend to produce better outputs.\\n\\nNote that these methods are specifically mentioned in the context provided. There may be other approaches to task decomposition as well.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are common ways of doing it?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don\\'t know the context of \"it\", but based on the provided context, it seems that \"it\" might refer to tool use, generative agents, or task decomposition. If it\\'s about tool use, common ways of doing it include equipping LLMs with external tools to extend their capabilities. For generative agents, common ways of doing it include combining LLM with memory, planning, and reflection mechanisms to enable agents to behave conditioned on past experience. If it\\'s about task decomposition, common ways of doing it include using simple prompting, task-specific instructions, or human inputs.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A new session\n",
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are common ways of doing it?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc456\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is Task Decomposition?'), AIMessage(content='Task decomposition is a process in which a complex task is broken down into smaller, more manageable subtasks or steps. This can be done by a Large Language Model (LLM) using simple prompting, task-specific instructions, or human inputs. The goal of task decomposition is to make it easier to solve the original task by focusing on one step at a time.'), HumanMessage(content='What are common ways of doing it?'), AIMessage(content='Common ways of doing task decomposition include:\\n\\n1. Chain of Thought (CoT): Instructing the model to \"think step by step\" to utilize more test-time computation and decompose hard tasks into smaller and simpler steps.\\n2. History-based prompting: Presenting a history of sequentially improved outputs in context and training the model to take on the trend to produce better outputs.\\n\\nNote that these methods are specifically mentioned in the context provided. There may be other approaches to task decomposition as well.')]),\n",
       " 'abc456': InMemoryChatMessageHistory(messages=[HumanMessage(content='What are common ways of doing it?'), AIMessage(content='I don\\'t know the context of \"it\", but based on the provided context, it seems that \"it\" might refer to tool use, generative agents, or task decomposition. If it\\'s about tool use, common ways of doing it include equipping LLMs with external tools to extend their capabilities. For generative agents, common ways of doing it include combining LLM with memory, planning, and reflection mechanisms to enable agents to behave conditioned on past experience. If it\\'s about task decomposition, common ways of doing it include using simple prompting, task-specific instructions, or human inputs.')])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
